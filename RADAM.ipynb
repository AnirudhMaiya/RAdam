{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RADAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m06nj5WwrlZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "a7c16f98-3dae-4319-ee9e-9bba48ab5d98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsihvohurxR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lxW0uv9rlob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/ML 5th sem proj/GALEX_data-extended-feats.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KFSiFq4ruer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data.iloc[:,1:25]\n",
        "y = data.iloc[:,0]\n",
        "\n",
        "x = (x.to_numpy())                     #features\n",
        "y = (y.to_numpy())                     #classes\n",
        "\n",
        "y = y.reshape(8406,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBzz4rbHrvzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardize the data for\n",
        "# 1)Faster Convergence\n",
        "# 2)Since scale of each attribute is not same\n",
        "# 3)Larger input values dominate the network otherwise\n",
        "\n",
        "#  Data point with non-zero mean value has a bigger eigenvalue, so the gradient of this point will shadow \n",
        "#  other data points and their gradients won't get updated, thus slowing the convergence\n",
        "\n",
        "x_copy = x.copy()\n",
        "\n",
        "for i in range(x.shape[1]):\n",
        "  x_copy[:,i] = (x[:,i] - np.mean(x[:,i])) / (np.std(x[:,i]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbiyhydwr3pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 80-20 split \n",
        "\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(x_copy, y, test_size=0.20, random_state=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns0iwT1kr6lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vecy_train = np.zeros((6724,3))\n",
        "for i in range(6724):\n",
        "  vecy_train[i,y_train[i]] = 1 \n",
        "  \n",
        "vecy_val = np.zeros((1682,3))\n",
        "for i in range(1682):\n",
        "  vecy_val[i,y_val[i]] = 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TB-LsOxr8P8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(array):\n",
        "  return (1 / (1 + np.exp(-array)))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(array):\n",
        "  return sigmoid(array) * (1 - sigmoid(array))\n",
        "\n",
        "\n",
        "def softmax(array):\n",
        "  numerator   = np.exp(array)\n",
        "  denominator = np.sum(numerator,axis = 1,keepdims=True)\n",
        "  return numerator / denominator\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klqiIC1Er-_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## number of Layers\n",
        "\n",
        "\n",
        "layers = [23,30,25,15,3]\n",
        "\n",
        "\n",
        "#23 is input layer\n",
        "#3 is output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UROqE5p-mqCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YxNYEkwsFcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "linear_Z    = {}\n",
        "nonlinear_A = {}\n",
        "weights     = {}\n",
        "gradients   = {}\n",
        "noise       = {}\n",
        "\n",
        "def initialize_layers(layers):\n",
        "  for i in range(0,len(layers)-1):\n",
        "    if(i == 0):\n",
        "      weights['W'+str(i+1)] = np.random.randn(layers[0],layers[1]) \n",
        "      #weights['W'+str(i+1)] = np.random.uniform(low=-0.5, high=0.5, size=(layers[0],layers[1]))\n",
        "      noise['b'+str(i+1)] = np.random.randn(layers[1]) * 0.1\n",
        "    else:\n",
        "      weights['W'+str(i+1)] = np.random.randn(layers[i],layers[i+1]) \n",
        "      #weights['W'+str(i+1)] = np.random.uniform(low=-0.5, high=0.5, size=(layers[i],layers[i+1]))\n",
        "      noise['b'+str(i+1)] = np.random.randn(layers[i+1]) * 0.1\n",
        "\n",
        "\n",
        "def linear_nonlinear_activation(layers,X_train,weights,linear_Z,nonlinear_A):\n",
        "  for i in range(0,len(layers)-2):\n",
        "    if(i == 0):\n",
        "      noise['b'+str(i+1)] = np.random.randn(layers[1]) * 0.1\n",
        "      linear_Z['Z'+str(i+1)] = np.dot(X_train, weights[\"W1\"]) + noise['b1']\n",
        "      nonlinear_A['A'+str(i+1)] = sigmoid(linear_Z['Z' + str(i+1)])\n",
        "\n",
        "    else:\n",
        "      noise['b'+str(i+1)] = np.random.randn(layers[i+1]) * 0.1\n",
        "      linear_Z['Z'+str(i+1)] = np.dot(nonlinear_A['A'+str(i)],weights['W'+str(i+1)]) + noise['b'+str(i+1)]\n",
        "      nonlinear_A['A'+str(i+1)] = sigmoid(linear_Z['Z' + str(i+1)])\n",
        "\n",
        "\n",
        "def backward(X_train,dZ3,weights,gradients,linear_Z,nonlinear_A,layers):\n",
        "  \n",
        "  \n",
        "  for i in range(len(layers)-1,1,-1):\n",
        "    if(i == len(layers)-1):\n",
        "      dZ_X = np.dot(dZ3,weights[\"W\"+str(i)].T) * sigmoid_derivative(linear_Z[\"Z\"+ str(i-1)])\n",
        "      gradients[\"dW\"+str(i-1)] = np.dot(nonlinear_A[\"A\"+str(i-2)].T,dZ_X)\n",
        "      \n",
        "    elif(i == 2):\n",
        "      dZ_X = np.dot(dZ_X,weights[\"W\"+str(i)].T) * sigmoid_derivative(linear_Z[\"Z\"+ str(i-1)])\n",
        "      gradients[\"dW\"+str(i-1)] = np.dot(X_train.T,dZ_X)\n",
        "      \n",
        "    else:\n",
        "      dZ_X = np.dot(dZ_X,weights[\"W\"+str(i)].T) * sigmoid_derivative(linear_Z[\"Z\"+ str(i-1)])\n",
        "      gradients[\"dW\"+str(i-1)] = np.dot(nonlinear_A[\"A\"+str(i-2)].T,dZ_X)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qULMnPAWsJOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def moment_initializer(weights) :\n",
        "\n",
        "    \n",
        "    first_moment = {}\n",
        "    second_moment = {}\n",
        "\n",
        "    for i in range(1,len(weights)+1):\n",
        "        first_moment[\"dW\" + str(i)] = np.zeros((weights[\"W\" + str(i)].shape[0],weights[\"W\" + str(i)].shape[1]))\n",
        "\n",
        "        second_moment[\"dW\" + str(i)] = np.zeros((weights[\"W\" + str(i)].shape[0],weights[\"W\" + str(i)].shape[1]))\n",
        "\n",
        "        \n",
        "    \n",
        "    return first_moment, second_moment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moOuTcz7sLMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initilization\n",
        "initialize_layers(layers)\n",
        "\n",
        "first_moment, second_moment = moment_initializer(weights)\n",
        "\n",
        "radam_params ={'beta1':0.9,\n",
        "              'beta2':0.99,\n",
        "              'smoothing_term':1e-8,\n",
        "              'learning_rate':0.0009,\n",
        "              'time_step':0,\n",
        "               'p_time':0,\n",
        "              'first_moment':first_moment,\n",
        "              'second_moment':second_moment}\n",
        "p_max = (2 / (1 - radam_params['beta2']) ) - 1\n",
        "radam_params['p_max'] = p_max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_zMN1dItvu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def radam(weights, gradients, first_moment, second_moment,p_max, time_step, learning_rate, beta1, beta2, smoothing_term=1e-8):\n",
        "\n",
        "    \n",
        "    first_moment_bias_correction = {}  \n",
        "    second_moment_bias_correction = {}           \n",
        "    \n",
        "    \n",
        "    p_time = p_max - ((( 2 * time_step * np.power(beta2,time_step))) / (1 - np.power(beta2,time_step)))\n",
        "    #print(p_time)\n",
        "    for i in range(1,len(weights)+1):\n",
        "\n",
        "        first_moment[\"dW\" + str(i)] = beta1 * first_moment[\"dW\" + str(i)] + (1 - beta1) * gradients['dW' + str(i)]\n",
        "        first_moment_bias_correction[\"dW\" + str(i)] = first_moment[\"dW\" + str(i)] / (1 - np.power(beta1, time_step))\n",
        "\n",
        "     \n",
        "        second_moment[\"dW\" + str(i)] = beta2 * second_moment[\"dW\" + str(i)] + (1 - beta2) * np.power(gradients['dW' + str(i)], 2)\n",
        "        \n",
        "        numerator = first_moment_bias_correction[\"dW\" + str(i)]\n",
        "        if(p_time > 4):\n",
        "          second_moment_bias_correction[\"dW\" + str(i)] = second_moment[\"dW\" + str(i)] / (1 - np.power(beta2, time_step))\n",
        "          denominator  = np.sqrt(second_moment_bias_correction[\"dW\" + str(i)] + smoothing_term)\n",
        "          r = ((p_time - 4)*(p_time-2)*p_max) / ((p_max-4)*(p_max - 2)*p_time)\n",
        "          weights[\"W\" + str(i)] = weights[\"W\" + str(i)] - ((learning_rate * r* numerator) / (denominator))  \n",
        "\n",
        "        else:\n",
        "          weights[\"W\" + str(i)] = weights[\"W\" + str(i)] - ((learning_rate * numerator))\n",
        "      \n",
        "          \n",
        "    \n",
        "        \n",
        "    \n",
        "      \n",
        "   \n",
        "\n",
        "    return weights, first_moment, second_moment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcA_RuB-tvrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdzYqk0rsMiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_acc():\n",
        "  c = 0\n",
        "  linear_nonlinear_activation(layers,X_train,weights,linear_Z,nonlinear_A)\n",
        "  \n",
        "  linear_Z['Z'+str(len(weights))] = np.dot(nonlinear_A[\"A\"+str(len(weights)-1)], weights['W'+str(len(weights))]) + noise['b'+str(len(noise))]\n",
        "  nonlinear_A[\"A\"+str(len(weights))] = softmax(linear_Z['Z'+str(len(weights))])\n",
        "    \n",
        "  \n",
        "  for i in range(X_train.shape[0]):\n",
        "    if(np.argmax(nonlinear_A[\"A\"+str(len(weights))][i]) == y_train[i]):\n",
        "      c = c+1\n",
        "  return c/X_train.shape[0], np.sum(-vecy_train * np.log(nonlinear_A['A'+str(len(weights))]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIPVXgVVsPBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def val_acc():\n",
        "  c = 0\n",
        "  linear_nonlinear_activation(layers,X_val,weights,linear_Z,nonlinear_A)\n",
        "  \n",
        "  linear_Z['Z'+str(len(weights))] = np.dot(nonlinear_A[\"A\"+str(len(weights)-1)], weights['W'+str(len(weights))])\n",
        "  nonlinear_A[\"A\"+str(len(weights))] = softmax(linear_Z['Z'+str(len(weights))])\n",
        "    \n",
        "  \n",
        "  for i in range(X_val.shape[0]):\n",
        "    if(np.argmax(nonlinear_A[\"A\"+str(len(weights))][i]) == y_val[i]):\n",
        "      c = c+1\n",
        "  return c/X_val.shape[0], np.sum(-vecy_val * np.log(nonlinear_A['A'+str(len(weights))]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piA-L6sJsX45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_function_train = []\n",
        "cost_function_val = []\n",
        "\n",
        "def train(layers,X_train,vecy_train,weights,gradients,linear_Z,nonlinear_A,radam_params,cost_function_train,cost_function_val,total_epochs):\n",
        "  \n",
        "  for k in range(total_epochs):\n",
        "  \n",
        "    #Forward Prop\n",
        "    linear_nonlinear_activation(layers,X_train,weights,linear_Z,nonlinear_A)\n",
        "    \n",
        "    \n",
        "    linear_Z['Z'+str(len(weights))] = np.dot(nonlinear_A[\"A\"+str(len(weights)-1)], weights['W'+str(len(weights))]) + noise['b'+str(len(noise))]\n",
        "    nonlinear_A[\"A\"+str(len(weights))] = softmax(linear_Z['Z'+str(len(weights))])\n",
        "      \n",
        "      \n",
        "    #Backprop\n",
        "    dZ3 = nonlinear_A[\"A\"+str(len(weights))] - vecy_train\n",
        "    gradients[\"dW\"+str(len(weights))] = np.dot(nonlinear_A[\"A\"+str(len(weights)-1)].T, dZ3)\n",
        "    backward(X_train,dZ3,weights,gradients,linear_Z,nonlinear_A,layers)\n",
        "    \n",
        "    radam_params[\"time_step\"] = radam_params[\"time_step\"] + 1\n",
        "    \n",
        "    \n",
        "    weights, radam_params[\"first_moment\"], radam_params[\"second_moment\"] = radam(weights, gradients, \n",
        "                                                                         radam_params[\"first_moment\"], radam_params[\"second_moment\"],\n",
        "                                                                         radam_params['p_max'],\n",
        "                                                                         radam_params[\"time_step\"], radam_params[\"learning_rate\"],\n",
        "                                                                         radam_params[\"beta1\"],radam_params[\"beta2\"],\n",
        "                                                                         \n",
        "                                                                         radam_params[\"smoothing_term\"])\n",
        "\n",
        "    if k % 100 == 0:\n",
        "        print(\"Epoch %d/%d \"%(k,total_epochs),end = ' ')\n",
        "        train_accuracy,train_loss = train_acc()\n",
        "        val_accuracy,val_loss = val_acc()\n",
        "        print('Loss: %f - train accuracy: %f - val_loss: %f - test/val accuracy: %f ' % (train_loss , train_accuracy ,val_loss,val_accuracy))\n",
        "        cost_function_train.append(train_loss)\n",
        "        cost_function_val.append(val_loss)\n",
        "\n",
        "  return cost_function_train,cost_function_val \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZlTqxU2R_f9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "021fd0c4-da6c-427e-dde1-0ced4dae7de6"
      },
      "source": [
        "loss_train,loss_val = train(layers,X_train,vecy_train,weights,gradients,linear_Z,nonlinear_A,radam_params,cost_function_train,cost_function_val,\n",
        "                     total_epochs = 2301)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2301  Loss: 48403.950374 - train accuracy: 0.658090 - val_loss: 11980.654949 - test/val accuracy: 0.662901 \n",
            "Epoch 100/2301  Loss: 9221.600292 - train accuracy: 0.644557 - val_loss: 2329.431496 - test/val accuracy: 0.645065 \n",
            "Epoch 200/2301  Loss: 8643.924810 - train accuracy: 0.658090 - val_loss: 2166.490730 - test/val accuracy: 0.662901 \n",
            "Epoch 300/2301  Loss: 7965.891703 - train accuracy: 0.658090 - val_loss: 2008.602077 - test/val accuracy: 0.662901 \n",
            "Epoch 400/2301  Loss: 7296.907440 - train accuracy: 0.771267 - val_loss: 1856.129227 - test/val accuracy: 0.693222 \n",
            "Epoch 500/2301  Loss: 6801.887310 - train accuracy: 0.846669 - val_loss: 1736.981847 - test/val accuracy: 0.843044 \n",
            "Epoch 600/2301  Loss: 6389.196226 - train accuracy: 0.848453 - val_loss: 1632.134657 - test/val accuracy: 0.846611 \n",
            "Epoch 700/2301  Loss: 5737.175343 - train accuracy: 0.845925 - val_loss: 1477.335887 - test/val accuracy: 0.843639 \n",
            "Epoch 800/2301  Loss: 4830.741223 - train accuracy: 0.849941 - val_loss: 1246.059858 - test/val accuracy: 0.846611 \n",
            "Epoch 900/2301  Loss: 4102.913655 - train accuracy: 0.849494 - val_loss: 1067.579807 - test/val accuracy: 0.845422 \n",
            "Epoch 1000/2301  Loss: 3419.518550 - train accuracy: 0.840720 - val_loss: 891.495341 - test/val accuracy: 0.836504 \n",
            "Epoch 1100/2301  Loss: 2829.862433 - train accuracy: 0.840869 - val_loss: 742.749224 - test/val accuracy: 0.837099 \n",
            "Epoch 1200/2301  Loss: 2441.672126 - train accuracy: 0.854551 - val_loss: 650.811379 - test/val accuracy: 0.847800 \n",
            "Epoch 1300/2301  Loss: 2209.526828 - train accuracy: 0.888013 - val_loss: 591.155709 - test/val accuracy: 0.856124 \n",
            "Epoch 1400/2301  Loss: 2071.851166 - train accuracy: 0.892029 - val_loss: 556.998811 - test/val accuracy: 0.886445 \n",
            "Epoch 1500/2301  Loss: 1973.241026 - train accuracy: 0.894111 - val_loss: 539.756281 - test/val accuracy: 0.887634 \n",
            "Epoch 1600/2301  Loss: 1897.297886 - train accuracy: 0.895747 - val_loss: 524.832004 - test/val accuracy: 0.891201 \n",
            "Epoch 1700/2301  Loss: 1833.706550 - train accuracy: 0.899762 - val_loss: 513.853741 - test/val accuracy: 0.892390 \n",
            "Epoch 1800/2301  Loss: 1788.295398 - train accuracy: 0.901249 - val_loss: 505.778954 - test/val accuracy: 0.894174 \n",
            "Epoch 1900/2301  Loss: 1742.326931 - train accuracy: 0.904075 - val_loss: 497.950779 - test/val accuracy: 0.892390 \n",
            "Epoch 2000/2301  Loss: 1710.394254 - train accuracy: 0.906008 - val_loss: 492.228627 - test/val accuracy: 0.897741 \n",
            "Epoch 2100/2301  Loss: 1709.840908 - train accuracy: 0.906901 - val_loss: 496.939486 - test/val accuracy: 0.897741 \n",
            "Epoch 2200/2301  Loss: 1668.912900 - train accuracy: 0.907496 - val_loss: 498.044430 - test/val accuracy: 0.900713 \n",
            "Epoch 2300/2301  Loss: 1651.141282 - train accuracy: 0.908239 - val_loss: 499.402540 - test/val accuracy: 0.892985 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADC-I55mcb2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}